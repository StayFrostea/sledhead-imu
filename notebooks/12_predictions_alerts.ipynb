{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 12: Predictions & Alerts\n",
        "\n",
        "Generate predictions on new data and produce alerts with bench recommendations.\n",
        "\n",
        "## Purpose\n",
        "\n",
        "1. **Load** trained Random Forest model and thresholds\n",
        "2. **Predict** severity (0-5) on new IMU data\n",
        "3. **Generate** alerts based on severity mapping\n",
        "4. **Output** actionable bench recommendations\n",
        "\n",
        "## Alert Action Items\n",
        "\n",
        "- **None (0-1)**: Continue training\n",
        "- **Low (2)**: Monitor athlete closely\n",
        "- **Medium (3)**: Consider reduced training\n",
        "- **High (4)**: Recommend bench / medical evaluation\n",
        "- **Critical (5)**: Immediate intervention required\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import json\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.append('../../src')\n",
        "\n",
        "from sledhead_imu.models.random_forest import predict_random_forest\n",
        "from sledhead_imu.alerts import generate_alerts_from_severity, summarize_alerts, get_critical_alerts\n",
        "\n",
        "# Setup paths\n",
        "data_dir = Path('../data')\n",
        "models_dir = data_dir / '10_models'\n",
        "validate_dir = data_dir / '11_metrics_validate_cutoffs'\n",
        "predictions_dir = data_dir / '12_predictions_alerts'\n",
        "\n",
        "# Load model\n",
        "model_file = models_dir / 'rf' / 'model.pkl'\n",
        "if model_file.exists():\n",
        "    with open(model_file, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    print(\"✓ Loaded trained Random Forest model\")\n",
        "else:\n",
        "    print(\"⚠️  Model not found. Run 10_train_random_forest.ipynb first.\")\n",
        "    model = None\n",
        "\n",
        "# Load severity mapping\n",
        "thresholds_file = validate_dir / 'thresholds' / 'severity_mapping.json'\n",
        "if thresholds_file.exists():\n",
        "    with open(thresholds_file, 'r') as f:\n",
        "        severity_mapping = json.load(f)\n",
        "    print(\"✓ Loaded severity-to-alert mapping\")\n",
        "else:\n",
        "    print(\"⚠️  Thresholds not found. Run 11_validate_define_cutoffs.ipynb first.\")\n",
        "    severity_mapping = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load new data for prediction\n",
        "# In production, this would be new IMU data processed through the pipeline\n",
        "\n",
        "if model is not None:\n",
        "    # For demo, use test set as \"new\" data\n",
        "    test_X_file = data_dir / '09_splits' / 'test' / 'X_test.csv'\n",
        "    \n",
        "    if test_X_file.exists():\n",
        "        X_new = pd.read_csv(test_X_file)\n",
        "        \n",
        "        # Generate predictions\n",
        "        severity_predictions = predict_random_forest(model, X_new)\n",
        "        \n",
        "        print(f\"✓ Generated predictions for {len(X_new)} samples\")\n",
        "        print(f\"\\nPredicted severity distribution:\")\n",
        "        severity_counts = pd.Series(severity_predictions).value_counts().sort_index()\n",
        "        for sev, count in severity_counts.items():\n",
        "            print(f\"  Severity {sev}: {count} samples\")\n",
        "    else:\n",
        "        print(\"⚠️  Test data not found. Skipping predictions.\")\n",
        "        severity_predictions = None\n",
        "else:\n",
        "    print(\"⚠️  Model not available. Skipping predictions.\")\n",
        "    severity_predictions = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate alerts from predictions\n",
        "if severity_predictions is not None and severity_mapping is not None:\n",
        "    # Create athlete IDs for demo\n",
        "    athlete_ids = [f\"A{i:04d}\" for i in range(len(severity_predictions))]\n",
        "    \n",
        "    # Generate alerts\n",
        "    alerts_df = generate_alerts_from_severity(\n",
        "        severity_predictions, \n",
        "        athlete_ids, \n",
        "        severity_mapping\n",
        "    )\n",
        "    \n",
        "    print(\"✓ Generated alerts\")\n",
        "    print(f\"\\nAlert summary:\")\n",
        "    alert_summary = summarize_alerts(alerts_df)\n",
        "    for level, count in sorted(alert_summary.items()):\n",
        "        print(f\"  {level.capitalize()}: {count} athletes\")\n",
        "    \n",
        "    # Show sample alerts\n",
        "    print(f\"\\nSample alerts (first 5 rows):\")\n",
        "    print(alerts_df[['athlete_id', 'severity', 'alert_level']].head().to_string(index=False))\n",
        "    \n",
        "else:\n",
        "    print(\"⚠️  Skipping alert generation - missing predictions or thresholds\")\n",
        "    alerts_df = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show critical alerts requiring immediate attention\n",
        "if alerts_df is not None:\n",
        "    critical = get_critical_alerts(alerts_df)\n",
        "    \n",
        "    if len(critical) > 0:\n",
        "        print(\"⚠️  CRITICAL ALERTS - IMMEDIATE ATTENTION REQUIRED\")\n",
        "        print(\"=\"*80)\n",
        "        print(critical[['athlete_id', 'severity', 'alert_level']].to_string(index=False))\n",
        "        print(f\"\\nAction: {len(critical)} athlete(s) require bench recommendation or medical evaluation\")\n",
        "    else:\n",
        "        print(\"✓ No critical alerts\")\n",
        "    \n",
        "    # Save outputs\n",
        "    predictions_dir.mkdir(parents=True, exist_ok=True)\n",
        "    outputs_dir = predictions_dir / 'outputs'\n",
        "    outputs_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    # Save all alerts\n",
        "    if alerts_df is not None:\n",
        "        alerts_df.to_csv(outputs_dir / 'all_alerts.csv', index=False)\n",
        "        print(f\"\\n✓ Saved all alerts to {outputs_dir / 'all_alerts.csv'}\")\n",
        "        \n",
        "        # Save critical alerts\n",
        "        if len(critical) > 0:\n",
        "            critical.to_csv(outputs_dir / 'critical_alerts.csv', index=False)\n",
        "            print(f\"✓ Saved critical alerts to {outputs_dir / 'critical_alerts.csv'}\")\n",
        "    \n",
        "    print(\"\\n✅ Predictions and alerts complete!\")\n",
        "else:\n",
        "    print(\"⚠️  No alerts generated\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
