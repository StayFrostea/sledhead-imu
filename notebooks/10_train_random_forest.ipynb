{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10: Random Forest Classifier\n",
        "\n",
        "Train and evaluate Random Forest classifier for head impact prediction.\n",
        "\n",
        "## Model Configuration\n",
        "\n",
        "- **Algorithm**: RandomForestClassifier from sklearn\n",
        "- **Task**: Classification (severity 0-5)\n",
        "- **Features**: 21 RF features\n",
        "- **Hyperparameters**:\n",
        "  - n_estimators: 100\n",
        "  - max_depth: 20\n",
        "  - class_weight: balanced (handles class imbalance)\n",
        "  - max_features: sqrt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.append('../../src')\n",
        "\n",
        "from sledhead_imu.models.random_forest import (\n",
        "    train_random_forest,\n",
        "    predict_random_forest,\n",
        "    evaluate_random_forest\n",
        ")\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load train/val/test splits\n",
        "data_dir = Path('../data')\n",
        "splits_dir = data_dir / '09_splits'\n",
        "models_dir = data_dir / '10_models'\n",
        "\n",
        "# Check if splits exist\n",
        "train_X_file = splits_dir / 'train' / 'X_train.csv'\n",
        "train_y_file = splits_dir / 'train' / 'y_train.csv'\n",
        "val_X_file = splits_dir / 'val' / 'X_val.csv'\n",
        "val_y_file = splits_dir / 'val' / 'y_val.csv'\n",
        "test_X_file = splits_dir / 'test' / 'X_test.csv'\n",
        "test_y_file = splits_dir / 'test' / 'y_test.csv'\n",
        "\n",
        "if all(f.exists() for f in [train_X_file, train_y_file, val_X_file, val_y_file]):\n",
        "    # Load splits\n",
        "    X_train = pd.read_csv(train_X_file)\n",
        "    y_train = pd.read_csv(train_y_file)\n",
        "    X_val = pd.read_csv(val_X_file)\n",
        "    y_val = pd.read_csv(val_y_file)\n",
        "    \n",
        "    # Handle DataFrame/series\n",
        "    if isinstance(y_train, pd.DataFrame):\n",
        "        y_train = y_train.iloc[:, 0]\n",
        "    if isinstance(y_val, pd.DataFrame):\n",
        "        y_val = y_val.iloc[:, 0]\n",
        "    \n",
        "    print(\"✓ Loaded splits\")\n",
        "    print(f\"  Train: {X_train.shape} features, {len(y_train)} samples\")\n",
        "    print(f\"  Val: {X_val.shape} features, {len(y_val)} samples\")\n",
        "    \n",
        "    if test_X_file.exists() and test_y_file.exists():\n",
        "        X_test = pd.read_csv(test_X_file)\n",
        "        y_test = pd.read_csv(test_y_file)\n",
        "        if isinstance(y_test, pd.DataFrame):\n",
        "            y_test = y_test.iloc[:, 0]\n",
        "        print(f\"  Test: {X_test.shape} features, {len(y_test)} samples\")\n",
        "    \n",
        "    print(f\"\\n✓ Feature columns: {list(X_train.columns)[:5]}... ({X_train.shape[1]} total)\")\n",
        "else:\n",
        "    print(\"⚠️  Splits not found. Run 09_train_test_split.ipynb first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest model\n",
        "if 'X_train' in locals():\n",
        "    print(\"Training Random Forest...\")\n",
        "    \n",
        "    config = {\n",
        "        'n_estimators': 100,\n",
        "        'max_depth': 20,\n",
        "        'min_samples_split': 2,\n",
        "        'min_samples_leaf': 1,\n",
        "        'class_weight': 'balanced',\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "    \n",
        "    model = train_random_forest(X_train, y_train, X_val, y_val, config)\n",
        "    \n",
        "    print(f\"✓ Model trained with {config['n_estimators']} trees\")\n",
        "    print(f\"  Max depth: {config['max_depth']}\")\n",
        "    print(f\"  Class weight: {config['class_weight']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on validation set\n",
        "if 'model' in locals() and 'X_val' in locals():\n",
        "    print(\"Evaluating on validation set...\")\n",
        "    \n",
        "    results = evaluate_random_forest(model, X_val, y_val)\n",
        "    \n",
        "    print(f\"\\n✓ Validation Accuracy: {results['accuracy']:.3f}\")\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(results['confusion_matrix'])\n",
        "    \n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(y_val, results['predictions']))\n",
        "    \n",
        "    print(f\"\\nTop 10 Feature Importances:\")\n",
        "    print(results['feature_importance'].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set (if available)\n",
        "if 'model' in locals() and 'X_test' in locals():\n",
        "    print(\"Evaluating on test set...\")\n",
        "    \n",
        "    test_results = evaluate_random_forest(model, X_test, y_test)\n",
        "    \n",
        "    print(f\"\\n✓ Test Accuracy: {test_results['accuracy']:.3f}\")\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(test_results['confusion_matrix'])\n",
        "    \n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, test_results['predictions']))\n",
        "else:\n",
        "    print(\"Test set not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model and results\n",
        "if 'model' in locals():\n",
        "    import pickle\n",
        "    import json\n",
        "    \n",
        "    models_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Save model\n",
        "    model_file = models_dir / 'rf' / 'model.pkl'\n",
        "    model_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(model_file, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "    print(f\"✓ Saved model to {model_file}\")\n",
        "    \n",
        "    # Save feature importances\n",
        "    if 'results' in locals():\n",
        "        feature_importance_file = models_dir / 'rf' / 'feature_importance.csv'\n",
        "        results['feature_importance'].to_csv(feature_importance_file, index=False)\n",
        "        print(f\"✓ Saved feature importances to {feature_importance_file}\")\n",
        "    \n",
        "    # Save config\n",
        "    config_file = models_dir / 'rf' / 'config.json'\n",
        "    config['model_type'] = 'RandomForestClassifier'\n",
        "    with open(config_file, 'w') as f:\n",
        "        json.dump(config, f, indent=2)\n",
        "    print(f\"✓ Saved config to {config_file}\")\n",
        "    \n",
        "    print(\"\\n✅ Model training and evaluation complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
